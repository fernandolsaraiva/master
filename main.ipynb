{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import hydroeval as he\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros para reprodutibilidade\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtenção dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = pd.read_csv ('data/series_temporais_tratadas_2018.csv').drop(['Unnamed: 0'],axis=1)\n",
    "df_2019 = pd.read_csv ('data/series_temporais_tratadas_2019.csv').drop(['Unnamed: 0'],axis=1)\n",
    "df_2020 = pd.read_csv ('data/series_temporais_tratadas_2020.csv').drop(['Unnamed: 0'],axis=1)\n",
    "df_2021 = pd.read_csv ('data/series_temporais_tratadas_2021.csv').drop(['Unnamed: 0'],axis=1)\n",
    "df_2022 = pd.read_csv ('data/series_temporais_tratadas_2022.csv').drop(['Unnamed: 0'],axis=1)\n",
    "df_2023 = pd.read_csv ('data/series_temporais_tratadas_2023.csv').drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective function of Random Forest for Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an objective function to be minimized\n",
    "def objective(trial):\n",
    "  # Setup values for the hyperparameters:\n",
    "  n_estimators = trial.suggest_int(\"n_estimators\", low = 50, high = 200, step = 50)\n",
    "  max_depth = trial.suggest_int(\"max_depth\", low = 2, high = 20, step = 1)\n",
    "  min_samples_split = trial.suggest_int(\"min_samples_split\", low = 2, high = 20, step = 1)\n",
    "  min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", low = 2, high = 20, step = 1)\n",
    "\n",
    "  regressor = RandomForestRegressor(n_jobs=-1,verbose=0,max_depth=max_depth, n_estimators=n_estimators,min_samples_split=min_samples_split,min_samples_leaf = min_samples_leaf, random_state = 42)\n",
    "\n",
    "  #Scoring method:\n",
    "  regressor.fit(X_train, y_train)\n",
    "  from sklearn.metrics import mean_squared_error as mse\n",
    "  # getting forecasts for the test set\n",
    "  predictions = regressor.predict(X_val)\n",
    "  # computing MSE error\n",
    "  mse = mse(predictions, y_val)\n",
    "  rmse = np.sqrt(mse)\n",
    "  score = rmse\n",
    "  return score\n",
    "\n",
    "def run_optuna(n_trials=50):\n",
    "  # Run Optuna\n",
    "  sampler = TPESampler(seed=10)  # Make the sampler behave in a deterministic way.\n",
    "  study = optuna.create_study(direction=\"minimize\",sampler=sampler)\n",
    "  #optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "  optuna.logging.set_verbosity(optuna.logging.WARNING) #essa linha suprime o print das infos\n",
    "  study.optimize(objective, n_trials=n_trials)\n",
    "  trial = study.best_trial\n",
    "  #print('RMSE: {}'.format(trial.value))\n",
    "  #print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "  #optuna.visualization.plot_optimization_history(study)\n",
    "  #optuna.visualization.plot_slice(study)\n",
    "  n_estimators = trial.params['n_estimators']\n",
    "  max_depth = trial.params['max_depth']\n",
    "  min_samples_split = trial.params['min_samples_split']\n",
    "  min_samples_leaf = trial.params['min_samples_leaf']\n",
    "  return trial, n_estimators, max_depth, min_samples_split, min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function of XGBoost for Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define an objective function to be minimized\n",
    "def objective_xgb(trial):\n",
    "  # Setup values for the hyperparameters:\n",
    "  # Adapted from https://practicaldatascience.co.uk/machine-learning/how-to-use-optuna-for-xgboost-hyperparameter-tuning\n",
    "  params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0,log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0,log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.01, 1.0,log=True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.01, 1.0,log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0,log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0,log=True),\n",
    "        'eval_metric': 'rmse'\n",
    "    }\n",
    "\n",
    "  regressor = xgb.XGBRegressor(objective = \"reg:squarederror\",random_state = 42,**params)\n",
    "  regressor.fit(X_train, y_train)\n",
    "  #Scoring method:\n",
    "  from sklearn.metrics import mean_squared_error as mse\n",
    "  # getting forecasts for the test set\n",
    "  predictions = regressor.predict(X_val)\n",
    "  # computing MSE error\n",
    "  mse = mse(predictions, y_val)\n",
    "  rmse = np.sqrt(mse)\n",
    "  score = rmse\n",
    "  return score\n",
    "\n",
    "def run_optuna_xgb(n_trials=50):\n",
    "  # Run Optuna\n",
    "  sampler = TPESampler(seed=10)  # Make the sampler behave in a deterministic way.\n",
    "  study = optuna.create_study(direction=\"minimize\",sampler=sampler)\n",
    "  optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "  #optuna.logging.set_verbosity(optuna.logging.WARNING) #essa linha suprime o print das infos\n",
    "  study.optimize(objective_xgb, n_trials=n_trials)\n",
    "  trial = study.best_trial\n",
    "  #print('RMSE: {}'.format(trial.value))\n",
    "  #print(\"Best hyperparameters: {}\".format(trial.params))\n",
    "  #optuna.visualization.plot_optimization_history(study)\n",
    "  #optuna.visualization.plot_slice(study)\n",
    "  max_depth = trial.params['max_depth']\n",
    "  learning_rate = trial.params['learning_rate']\n",
    "  n_estimators = trial.params['n_estimators']\n",
    "  min_child_weight = trial.params['min_child_weight']\n",
    "  gamma = trial.params['gamma']\n",
    "  subsample = trial.params['subsample']\n",
    "  colsample_bytree = trial.params['colsample_bytree']\n",
    "  reg_alpha = trial.params['reg_alpha']\n",
    "  reg_lambda = trial.params['reg_lambda']\n",
    "  return trial, max_depth, learning_rate , n_estimators, min_child_weight, gamma,subsample, colsample_bytree, reg_alpha, reg_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit e evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_rf(X_train,y_train,random_state = 42):\n",
    "    model = RandomForestRegressor(n_jobs=-1, verbose=0,random_state=random_state)\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    importances = model.feature_importances_\n",
    "    return model, importances\n",
    "\n",
    "def training_xgb(X_train, y_train,random_state = 42):\n",
    "    model = xgb.XGBRegressor(objective=\"reg:squarederror\",random_state=random_state)\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    importances = model.feature_importances_\n",
    "    return model, importances\n",
    "\n",
    "def training_lgb(X_train, y_train,random_state = 42):\n",
    "    model = lgb.LGBMRegressor(objective = 'regression',metric='rmse',random_state=random_state,verbose = 0)\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    importances = model.feature_importances_\n",
    "    return model, importances\n",
    "\n",
    "def training_cb(X_train,y_train,random_state = 42):\n",
    "    model = cb.CatBoostRegressor(loss_function='RMSE',random_state=random_state,verbose = 0)\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    importances = model.feature_importances_\n",
    "    return model, importances\n",
    "\n",
    "\n",
    "def predictions(X_train,y_train,X_val,y_val,model):\n",
    "    prediction = model.predict(X_val)\n",
    "    mse = mean_squared_error(prediction, y_val)\n",
    "    rmse = np.sqrt(mse)\n",
    "    nse = he.evaluator(he.nse, prediction, y_val)\n",
    "    nse = nse[0]\n",
    "    prediction_train = model.predict(X_train)\n",
    "    mse_train = mean_squared_error(prediction_train, y_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    nse_train = he.evaluator(he.nse, prediction_train, y_train)\n",
    "    nse_train = nse_train[0]\n",
    "\n",
    "    # print(\"Root mean squared error (RMSE) on train set: {:.4f}\".format(rmse_train))\n",
    "    # print(f\"Nash-Sutcliffe-Efficience (NSE) on train set: {nse_train}\")\n",
    "    # print(\"Root mean squared error (RMSE) on test set: {:.4f}\".format(rmse))\n",
    "    # print(f\"Nash-Sutcliffe-Efficience (NSE) on test set: {nse}\")\n",
    "\n",
    "    return prediction, rmse, nse\n",
    "\n",
    "\n",
    "def plot_results(prediction,y_val,nse):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(prediction,color='orange',label='predicted')\n",
    "    plt.plot(y_val,label='actual')\n",
    "    plt.title(f'Actual and predicted river level at station 413 for the test set, NSE = {nse}',fontsize=18)\n",
    "    plt.ylabel('River level (cm)',fontsize=14)\n",
    "    plt.xlabel('Time stamp',fontsize=14)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_val, prediction, c='r',s=5)\n",
    "    p1 = max(max(prediction), max(y_val))\n",
    "    p2 = min(min(prediction), min(y_val))\n",
    "    plt.plot([p1, p2], [p1, p2], 'b-')\n",
    "    plt.xlabel('Actual', fontsize=15)\n",
    "    plt.ylabel('Predicted', fontsize=15)\n",
    "    plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Delay Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_delay_embedding(series: pd.Series, n_lags: int, horizon: int):\n",
    "    \"\"\"\n",
    "    Time delay embedding\n",
    "    Time series for supervised learning\n",
    "    :param series: time series as pd.Series\n",
    "    :param n_lags: number of past values to used as explanatory variables\n",
    "    :param horizon: how many values to forecast\n",
    "    :return: pd.DataFrame with reconstructed time series\n",
    "    \"\"\"\n",
    "    assert isinstance(series, pd.Series)\n",
    "\n",
    "    if series.name is None:\n",
    "        name = 'Series'\n",
    "    else:\n",
    "        name = series.name\n",
    "\n",
    "    n_lags_iter = list(range(n_lags, -horizon, -1))\n",
    "\n",
    "    X = [series.shift(i) for i in n_lags_iter]\n",
    "    X = pd.concat(X, axis=1).dropna()\n",
    "    X.columns = [f'{name}(t-{j - 1})'\n",
    "                 if j > 0 else f'{name}(t+{np.abs(j) + 1})'\n",
    "                 for j in n_lags_iter]\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação dos Conjuntos de Treinament/Validação/Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_dataframes(dataframes_treinamento, dataframes_validacao, dataframes_teste,horizon=12):\n",
    "  # Conjunto de treinamento\n",
    "  df_treinamento = pd.DataFrame()\n",
    "  dataframes = dataframes_treinamento\n",
    "\n",
    "  for df in dataframes:\n",
    "    train = df\n",
    "    train = train.set_index(['intervalo'])\n",
    "\n",
    "    # create data set with lagged features using time delay embedding\n",
    "    train_ds = []\n",
    "    for col in train:\n",
    "      col_df = time_delay_embedding(train[col], n_lags=12, horizon=horizon)\n",
    "      train_ds.append(col_df)\n",
    "\n",
    "    # Concatenating all variables\n",
    "    train_df = pd.concat(train_ds, axis=1)\n",
    "\n",
    "    df_treinamento = pd.concat([df_treinamento, train_df])\n",
    "  train_df = df_treinamento\n",
    "\n",
    "  # Conjunto de validação\n",
    "  df_validacao = pd.DataFrame()\n",
    "  dataframes = dataframes_validacao\n",
    "\n",
    "  for df in dataframes:\n",
    "    val = df\n",
    "    val = val.set_index(['intervalo'])\n",
    "    # create data set with lagged features using time delay embedding\n",
    "    val_ds = []\n",
    "    for col in val:\n",
    "      col_df = time_delay_embedding(val[col], n_lags=12, horizon=horizon)\n",
    "      val_ds.append(col_df)\n",
    "\n",
    "    # Concatenating all variables\n",
    "    val_df = pd.concat(val_ds, axis=1)\n",
    "\n",
    "    df_validacao = pd.concat([df_validacao, val_df])\n",
    "  val_df = df_validacao\n",
    "\n",
    "  # Conjunto de teste\n",
    "  test = df_2023\n",
    "  test = test.set_index(['intervalo'])\n",
    "\n",
    "  # create data set with lagged features using time delay embedding\n",
    "  test_ds = []\n",
    "  for col in test:\n",
    "    col_df = time_delay_embedding(test[col], n_lags=12, horizon=horizon)\n",
    "    test_ds.append(col_df)\n",
    "\n",
    "  # Concatenating all variables\n",
    "  test_df = pd.concat(test_ds, axis=1)\n",
    "\n",
    "  return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_conjuntos(train_df,val_df,test_df,horizon=12):\n",
    "  # Treinamento - defining target (Y) and explanatory variables (X)\n",
    "  predictor_variables = train_df.columns.str.contains('-')\n",
    "  target_variables = train_df.columns.str.contains(f'valor_leitura_flu_413(t+{horizon}',regex=False)\n",
    "\n",
    "  X_train = train_df.iloc[:, predictor_variables]\n",
    "  y_train = train_df.iloc[:, target_variables]\n",
    "  # Validação - defining target (Y) and explanatory variables (X)\n",
    "  predictor_variables = val_df.columns.str.contains('-')\n",
    "  target_variables = val_df.columns.str.contains(f'valor_leitura_flu_413(t+{horizon}',regex=False)\n",
    "\n",
    "  X_val = val_df.iloc[:, predictor_variables]\n",
    "  y_val = val_df.iloc[:, target_variables]\n",
    "  # Teste - defining target (Y) and explanatory variables (X)\n",
    "  predictor_variables = test_df.columns.str.contains('-')\n",
    "  target_variables = train_df.columns.str.contains(f'valor_leitura_flu_413(t+{horizon}',regex=False)\n",
    "\n",
    "  X_test = test_df.iloc[:, predictor_variables]\n",
    "  y_test = test_df.iloc[:, target_variables]\n",
    "\n",
    "  return X_train,y_train,X_val,y_val,X_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp. 5 - Markoviano (com treino em 2018/2019 e validação em 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = preparar_dataframes(dataframes_treinamento = [df_2018, df_2019], dataframes_validacao = [df_2020], dataframes_teste = [df_2023])\n",
    "X_train_general,y_train_general,X_val_general,y_val_general,X_test_general,y_test_general = gerar_conjuntos(train_df,val_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas = []\n",
    "entradas.append('valor_leitura_flu_413(t-0)')\n",
    "X_train_general.columns\n",
    "for nome in X_train_general.columns:\n",
    "  if ('plu' in nome and '-0' in nome):\n",
    "    entradas.append(nome)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train_general[entradas])\n",
    "X_val = np.array(X_val_general[entradas])\n",
    "X_test = np.array(X_test_general[entradas])\n",
    "y_train = np.array(y_train_general.values)\n",
    "y_val = np.array(y_val_general.values)\n",
    "y_test = np.array(y_test_general.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of RMSE: 44.5880223153191\n",
      "Average of NSE: 0.8098126842417245\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rmse_mean = 0\n",
    "nse_mean = 0\n",
    "total_iter = 30\n",
    "for i in range(total_iter):\n",
    "    model, importances = training_rf(X_train,y_train)\n",
    "    prediction, rmse, nse = predictions(X_train,y_train,X_val,y_val,model)\n",
    "    #plot_results(prediction,y_val,nse)\n",
    "    rmse_mean += rmse\n",
    "    nse_mean += nse\n",
    "rmse_mean = rmse_mean/total_iter\n",
    "nse_mean = nse_mean/total_iter\n",
    "print('Average of RMSE:', rmse_mean)\n",
    "print('Average of NSE:',nse_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of RMSE: 44.39246427709734\n",
      "Average of NSE: 0.8114773060407817\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "rmse_mean = 0\n",
    "nse_mean = 0\n",
    "total_iter = 30\n",
    "for i in range(total_iter):\n",
    "    model, importances = training_xgb(X_train,y_train)\n",
    "    prediction, rmse, nse = predictions(X_train,y_train,X_val,y_val,model)\n",
    "    #plot_results(prediction,y_val,nse)\n",
    "    rmse_mean += rmse\n",
    "    nse_mean += nse\n",
    "rmse_mean = rmse_mean/total_iter\n",
    "nse_mean = nse_mean/total_iter\n",
    "print('Average of RMSE:', rmse_mean)\n",
    "print('Average of NSE:',nse_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of RMSE: 43.24613544179031\n",
      "Average of NSE: 0.8210878899795528\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "rmse_mean = 0\n",
    "nse_mean = 0\n",
    "total_iter = 30\n",
    "for i in range(total_iter):\n",
    "    model, importances = training_lgb(X_train,y_train)\n",
    "    prediction, rmse, nse = predictions(X_train,y_train,X_val,y_val,model)\n",
    "    #plot_results(prediction,y_val,nse)\n",
    "    rmse_mean += rmse\n",
    "    nse_mean += nse\n",
    "rmse_mean = rmse_mean/total_iter\n",
    "nse_mean = nse_mean/total_iter\n",
    "print('Average of RMSE:', rmse_mean)\n",
    "print('Average of NSE:',nse_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of RMSE: 42.8902341262595\n",
      "Average of NSE: 0.8240205470785541\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "rmse_mean = 0\n",
    "nse_mean = 0\n",
    "total_iter = 30\n",
    "for i in range(total_iter):\n",
    "    model, importances = training_cb(X_train,y_train)\n",
    "    prediction, rmse, nse = predictions(X_train,y_train,X_val,y_val,model)\n",
    "    #plot_results(prediction,y_val,nse)\n",
    "    rmse_mean += rmse\n",
    "    nse_mean += nse\n",
    "rmse_mean = rmse_mean/total_iter\n",
    "nse_mean = nse_mean/total_iter\n",
    "print('Average of RMSE:', rmse_mean)\n",
    "print('Average of NSE:',nse_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp. 5 - Com lag features (com treino em 2018/2019 e validação em 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando todas as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = preparar_dataframes(dataframes_treinamento = [df_2018, df_2019], dataframes_validacao = [df_2020], dataframes_teste = [df_2023])\n",
    "X_train_general,y_train_general,X_val_general,y_val_general,X_test_general,y_test_general = gerar_conjuntos(train_df,val_df,test_df)\n",
    "\n",
    "entradas = []\n",
    "X_train_general.columns\n",
    "for nome in X_train_general.columns:\n",
    "  if ('plu' in nome) or ('valor_leitura_flu_413' in nome):\n",
    "    entradas.append(nome)\n",
    "\n",
    "X_train_general = X_train_general[entradas]\n",
    "X_val_general = X_val_general[entradas]\n",
    "X_test_general = X_test_general[entradas]\n",
    "\n",
    "X_train = np.array(X_train_general)\n",
    "X_val = np.array(X_val_general)\n",
    "X_test = np.array(X_test_general)\n",
    "y_train = np.array(y_train_general.values).ravel()\n",
    "y_val = np.array(y_val_general.values).ravel()\n",
    "y_test = np.array(y_test_general.values).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of RMSE: 41.86234669179654\n",
      "Average of NSE: 0.8323543575265764\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rmse_mean = 0\n",
    "nse_mean = 0\n",
    "total_iter = 3\n",
    "for i in range(total_iter):\n",
    "    model, importances = training_rf(X_train,y_train)\n",
    "    prediction, rmse, nse = predictions(X_train,y_train,X_val,y_val,model)\n",
    "    #plot_results(prediction,y_val,nse)\n",
    "    rmse_mean += rmse\n",
    "    nse_mean += nse\n",
    "rmse_mean = rmse_mean/total_iter\n",
    "nse_mean = nse_mean/total_iter\n",
    "print('Average of RMSE:', rmse_mean)\n",
    "print('Average of NSE:',nse_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of RMSE: 41.49677372371826\n",
      "Average of NSE: 0.8352695841905309\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "rmse_mean = 0\n",
    "nse_mean = 0\n",
    "total_iter = 3\n",
    "for i in range(total_iter):\n",
    "    model, importances = training_xgb(X_train,y_train)\n",
    "    prediction, rmse, nse = predictions(X_train,y_train,X_val,y_val,model)\n",
    "    #plot_results(prediction,y_val,nse)\n",
    "    rmse_mean += rmse\n",
    "    nse_mean += nse\n",
    "rmse_mean = rmse_mean/total_iter\n",
    "nse_mean = nse_mean/total_iter\n",
    "print('Average of RMSE:', rmse_mean)\n",
    "print('Average of NSE:',nse_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of RMSE: 40.22019440446573\n",
      "Average of NSE: 0.8452490013851118\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "rmse_mean = 0\n",
    "nse_mean = 0\n",
    "total_iter = 3\n",
    "for i in range(total_iter):\n",
    "    model, importances = training_lgb(X_train,y_train)\n",
    "    prediction, rmse, nse = predictions(X_train,y_train,X_val,y_val,model)\n",
    "    #plot_results(prediction,y_val,nse)\n",
    "    rmse_mean += rmse\n",
    "    nse_mean += nse\n",
    "rmse_mean = rmse_mean/total_iter\n",
    "nse_mean = nse_mean/total_iter\n",
    "print('Average of RMSE:', rmse_mean)\n",
    "print('Average of NSE:',nse_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of RMSE: 39.40096291510712\n",
      "Average of NSE: 0.8514889390681347\n"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "rmse_mean = 0\n",
    "nse_mean = 0\n",
    "total_iter = 3\n",
    "for i in range(total_iter):\n",
    "    model, importances = training_cb(X_train,y_train)\n",
    "    prediction, rmse, nse = predictions(X_train,y_train,X_val,y_val,model)\n",
    "    #plot_results(prediction,y_val,nse)\n",
    "    rmse_mean += rmse\n",
    "    nse_mean += nse\n",
    "rmse_mean = rmse_mean/total_iter\n",
    "nse_mean = nse_mean/total_iter\n",
    "print('Average of RMSE:', rmse_mean)\n",
    "print('Average of NSE:',nse_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tamanduatei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
